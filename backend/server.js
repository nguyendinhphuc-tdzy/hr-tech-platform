require('dotenv').config();
const express = require('express');
const cors = require('cors');
const { Pool } = require('pg');
const multer = require('multer');
const pdfParse = require('pdf-parse'); 
const mammoth = require('mammoth'); // ƒê·ªçc file Word (Training)
const { GoogleGenerativeAI } = require("@google/generative-ai");

const app = express();
app.use(cors());
app.use(express.json());

// D√πng Memory Storage ƒë·ªÉ tr√°nh l·ªói ·ªï c·ª©ng tr√™n Render
const storage = multer.memoryStorage();
const upload = multer({ storage: storage });

const pool = new Pool({
  connectionString: process.env.DATABASE_URL,
  ssl: { rejectUnauthorized: false }
});

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);

// --- H√ÄM H·ªñ TR·ª¢ CHUNG ---

// 1. Chia nh·ªè vƒÉn b·∫£n (Cho Training)
function chunkText(text, chunkSize = 1000) {
    const chunks = [];
    let currentChunk = "";
    const sentences = text.split(/(?<=[.?!])\s+/);
    for (const sentence of sentences) {
        if ((currentChunk + sentence).length > chunkSize) {
            chunks.push(currentChunk);
            currentChunk = sentence;
        } else { currentChunk += " " + sentence; }
    }
    if (currentChunk) chunks.push(currentChunk);
    return chunks;
}

// 2. T·∫°o Vector Embedding (Cho Training & Chat)
async function createEmbedding(text) {
    const model = genAI.getGenerativeModel({ model: "text-embedding-004" });
    const result = await model.embedContent(text);
    return result.embedding.values;
}

// 3. Ph√¢n t√≠ch CV (Cho Scan CV)
async function analyzeCV(text) {
    try {
        const model = genAI.getGenerativeModel({ model: "gemini-1.5-flash" });
        const prompt = `B·∫°n l√† HR. Ph√¢n t√≠ch CV n√†y v√† tr·∫£ v·ªÅ JSON: 
        { "full_name": "...", "email": "...", "skills": [], "score": 0, "summary": "..." }
        N·ªôi dung: ${text.substring(0, 15000)}`;
        const result = await model.generateContent(prompt);
        const txt = result.response.text().replace(/```json|```/g, '').trim();
        return JSON.parse(txt);
    } catch (e) { return { skills: [], score: 0, summary: "L·ªói AI", full_name: null }; }
}

// =======================
// C√ÅC API (ENDPOINTS)
// =======================

// 1. API Scan CV
app.post('/api/cv/upload', upload.single('cv_file'), async (req, res) => {
    try {
        if (!req.file) return res.status(400).json({ error: 'Thi·∫øu file CV' });
        
        let rawText = "";
        try {
            const pdfData = await pdfParse(req.file.buffer);
            rawText = pdfData.text;
        } catch (e) { return res.status(400).json({ error: "L·ªói ƒë·ªçc PDF" }); }

        const aiResult = await analyzeCV(rawText);
        const finalName = req.body.full_name || aiResult.full_name || "·ª®ng vi√™n";
        
        const result = await pool.query(
            `INSERT INTO candidates (organization_id, full_name, email, role, status, ai_rating, ai_analysis) 
             VALUES (1, $1, $2, '·ª®ng vi√™n', 'Screening', $3, $4) RETURNING *`,
            [finalName, aiResult.email, aiResult.score, JSON.stringify(aiResult)]
        );
        res.json({ message: "Th√†nh c√¥ng!", candidate: result.rows[0] });
    } catch (err) { res.status(500).json({ error: err.message }); }
});

// 2. API L·∫•y danh s√°ch CV
app.get('/api/candidates', async (req, res) => {
    try {
        const result = await pool.query('SELECT * FROM candidates ORDER BY id DESC');
        res.json(result.rows);
    } catch (err) { res.status(500).send(err.message); }
});

// 3. API Training (Upload T√†i li·ªáu) - C√ÅI B·∫†N ƒêANG THI·∫æU
app.post('/api/training/upload', upload.single('doc_file'), async (req, res) => {
    try {
        if (!req.file) return res.status(400).json({ error: 'Thi·∫øu file t√†i li·ªáu' });
        
        console.log(`üìö ƒêang h·ªçc: ${req.file.originalname}`);
        let rawText = "";

        if (req.file.mimetype === 'application/pdf') {
            const pdfData = await pdfParse(req.file.buffer);
            rawText = pdfData.text;
        } else if (req.file.mimetype.includes('word') || req.file.originalname.endsWith('.docx')) {
            const result = await mammoth.extractRawText({ buffer: req.file.buffer });
            rawText = result.value;
        } else {
            return res.status(400).json({ error: "Ch·ªâ h·ªó tr·ª£ PDF v√† DOCX" });
        }

        const chunks = chunkText(rawText);
        for (const chunk of chunks) {
            if (!chunk.trim()) continue;
            const vector = await createEmbedding(chunk);
            await pool.query(
                `INSERT INTO documents (content, metadata, embedding) VALUES ($1, $2, $3)`,
                [chunk, JSON.stringify({ filename: req.file.originalname }), `[${vector.join(',')}]`]
            );
        }
        res.json({ message: `ƒê√£ h·ªçc xong ${chunks.length} ƒëo·∫°n ki·∫øn th·ª©c m·ªõi!` });
    } catch (err) { 
        console.error(err);
        res.status(500).json({ error: "L·ªói Training: " + err.message }); 
    }
});

// 4. API Chat v·ªõi AI
app.post('/api/training/chat', async (req, res) => {
    try {
        const { query } = req.body;
        const queryVector = await createEmbedding(query);

        // G·ªçi h√†m match_documents trong Supabase
        const searchResult = await pool.query(
            `select content from match_documents($1, 0.5, 5)`,
            [`[${queryVector.join(',')}]`]
        );

        const context = searchResult.rows.map(r => r.content).join("\n---\n");
        const model = genAI.getGenerativeModel({ model: "gemini-1.5-flash" });
        
        const result = await model.generateContent(`
            D·ª±a v√†o t√†i li·ªáu sau: ${context}
            H√£y tr·∫£ l·ªùi c√¢u h·ªèi: ${query}
        `);
        
        res.json({ answer: result.response.text() });
    } catch (err) { res.status(500).json({ error: err.message }); }
});

const PORT = process.env.PORT || 5000;
app.listen(PORT, () => {
    console.log(`Server ch·∫°y t·∫°i c·ªïng ${PORT}`);
});