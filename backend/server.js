/* FILE: backend/server.js (Phi√™n b·∫£n JSON Mode - Ch·ªëng l·ªói c√∫ ph√°p) */
require('dotenv').config();
const express = require('express');
const cors = require('cors');
const { Pool } = require('pg');
const multer = require('multer');
const fs = require('fs'); 
const csv = require('csv-parser');
const mammoth = require('mammoth'); 
const pdf = require('pdf-parse'); 
const { GoogleGenerativeAI } = require("@google/generative-ai");
const axios = require('axios');

const app = express();
app.use(cors());
app.use(express.json());

// --- C·∫§U H√åNH M·∫∂C ƒê·ªäNH ---
let ACTIVE_MODEL_NAME = "gemini-1.5-flash"; 

const storage = multer.memoryStorage();
const upload = multer({ storage: storage });

const pool = new Pool({
  connectionString: process.env.DATABASE_URL,
  ssl: { rejectUnauthorized: false }
});

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);

// --- T·ª∞ ƒê·ªòNG CH·ªåN MODEL (GI·ªÆ L·∫†I V√å N√ì ƒêANG CH·∫†Y T·ªêT) ---
async function checkAvailableModels() {
    try {
        console.log("üîç ƒêang ki·ªÉm tra Model...");
        const url = `https://generativelanguage.googleapis.com/v1beta/models?key=${process.env.GEMINI_API_KEY}`;
        const response = await axios.get(url);
        const models = response.data.models || [];
        
        // Danh s√°ch ∆∞u ti√™n (M·ªõi -> C≈©)
        const priority = ["gemini-2.0-flash", "gemini-1.5-pro", "gemini-1.5-flash", "gemini-1.0-pro"];
        
        const availableNames = models.map(m => m.name.replace('models/', ''));
        
        for (const p of priority) {
            if (availableNames.some(n => n.includes(p))) {
                ACTIVE_MODEL_NAME = p;
                // Fix cho tr∆∞·ªùng h·ª£p 1.5 flash c·∫ßn version c·ª• th·ªÉ
                if(p === "gemini-1.5-flash") ACTIVE_MODEL_NAME = "gemini-1.5-flash-001";
                break;
            }
        }
        console.log(`‚úÖ ƒê√£ ch·ªçn Model: ${ACTIVE_MODEL_NAME}`);
    } catch (e) {
        console.log(`‚ö†Ô∏è L·ªói check model, d√πng m·∫∑c ƒë·ªãnh: ${ACTIVE_MODEL_NAME}`);
    }
}
checkAvailableModels();

// --- H√ÄM L√ÄM S·∫†CH JSON (PH√íNG H·ªú) ---
function cleanJsonString(text) {
    // X√≥a markdown ```json ... ```
    let clean = text.replace(/```json/g, '').replace(/```/g, '').trim();
    // T√¨m ƒëi·ªÉm b·∫Øt ƒë·∫ßu { v√† k·∫øt th√∫c }
    const firstOpen = clean.indexOf('{');
    const lastClose = clean.lastIndexOf('}');
    if (firstOpen !== -1 && lastClose !== -1) {
        clean = clean.substring(firstOpen, lastClose + 1);
    }
    return clean;
}

// ==========================================
// C√ÅC H√ÄM H·ªñ TR·ª¢
// ==========================================
async function readPdfBuffer(buffer) {
    try { return (await pdf(buffer)).text; } catch (e) { return ""; }
}

function chunkText(text) {
    const chunks = []; let cur = ""; 
    text.split(/(?<=[.?!])\s+/).forEach(s => {
        if ((cur + s).length > 1000) { chunks.push(cur); cur = s; } else cur += " " + s;
    });
    if (cur) chunks.push(cur);
    return chunks;
}

async function createEmbedding(text) {
    const model = genAI.getGenerativeModel({ model: "text-embedding-004" });
    const result = await model.embedContent(text);
    return result.embedding.values;
}

// ==========================================
// API 1: SCAN CV (FIX L·ªñI JSON PARSE)
// ==========================================
app.post('/api/cv/upload', upload.single('cv_file'), async (req, res) => {
    try {
        if (!req.file) return res.status(400).json({ error: 'Thi·∫øu file CV' });
        console.log(`ü§ñ Processing CV with ${ACTIVE_MODEL_NAME}`);

        const jobId = req.body.job_id;
        let jobCriteria = null;
        if (jobId) {
            const jobRes = await pool.query('SELECT * FROM job_positions WHERE id = $1', [jobId]);
            if (jobRes.rows.length > 0) jobCriteria = jobRes.rows[0];
        }

        // --- C·∫§U H√åNH JSON MODE (CH√åA KH√ìA S·ª¨A L·ªñI) ---
        const model = genAI.getGenerativeModel({ 
            model: ACTIVE_MODEL_NAME,
            generationConfig: { responseMimeType: "application/json" } // <--- D√íNG QUAN TR·ªåNG NH·∫§T
        });
        
        let prompt = `B·∫°n l√† chuy√™n gia HR. Tr√≠ch xu·∫•t th√¥ng tin t·ª´ CV ƒë√≠nh k√®m.`;
        if (jobCriteria) {
            prompt += ` So s√°nh v·ªõi JD: ${jobCriteria.title}, K·ªπ nƒÉng: ${JSON.stringify(jobCriteria.requirements)}.`;
        }

        // Y√™u c·∫ßu output c·ª±c k·ª≥ ƒë∆°n gi·∫£n ƒë·ªÉ tr√°nh l·ªói c√∫ ph√°p
        prompt += `
        Output JSON format:
        {
            "full_name": "T√™n",
            "email": "Email",
            "skills": ["Skill1", "Skill2"],
            "score": 8.5,
            "summary": "T√≥m t·∫Øt",
            "match_reason": "L√Ω do ƒëi·ªÉm s·ªë"
        }
        `;

        const imageParts = [{
            inlineData: {
                data: req.file.buffer.toString("base64"),
                mimeType: req.file.mimetype,
            },
        }];

        const result = await model.generateContent([prompt, ...imageParts]);
        const responseText = result.response.text();
        
        console.log("üì¶ AI Raw Response:", responseText.substring(0, 100)); // Log ƒë·ªÉ debug

        // Parse an to√†n
        let aiResult;
        try {
            aiResult = JSON.parse(cleanJsonString(responseText));
        } catch (parseError) {
            console.error("‚ùå L·ªói Parse JSON:", parseError);
            // Fallback th·ªß c√¥ng n·∫øu v·∫´n l·ªói
            aiResult = { 
                full_name: "·ª®ng vi√™n (L·ªói ƒë·ªçc)", 
                score: 0, 
                summary: "AI tr·∫£ v·ªÅ d·ªØ li·ªáu kh√¥ng ƒë√∫ng ƒë·ªãnh d·∫°ng JSON.",
                email: null
            };
        }

        // L∆∞u DB
        const finalName = req.body.full_name || aiResult.full_name || "·ª®ng vi√™n M·ªõi";
        const finalScore = aiResult.score > 10 ? (aiResult.score / 10).toFixed(1) : aiResult.score;

        const dbResult = await pool.query(
            `INSERT INTO candidates (organization_id, job_id, full_name, email, role, status, ai_rating, ai_analysis) 
             VALUES (1, $1, $2, $3, $4, 'Screening', $5, $6) RETURNING *`,
            [
                jobId || null,
                finalName, 
                aiResult.email, 
                jobCriteria ? jobCriteria.title : '·ª®ng vi√™n t·ª± do', 
                finalScore, 
                JSON.stringify(aiResult)
            ]
        );

        res.json({ message: "Th√†nh c√¥ng!", candidate: dbResult.rows[0] });

    } catch (err) { 
        console.error("üî• L·ªói Server:", err);
        res.status(500).json({ error: "AI Error: " + err.message }); 
    }
});

// ... (Gi·ªØ nguy√™n c√°c API kh√°c y h·ªát c≈©) ...
app.get('/api/candidates', async (req, res) => {
    const result = await pool.query('SELECT * FROM candidates ORDER BY id DESC');
    res.json(result.rows);
});
app.get('/api/jobs', async (req, res) => {
    const result = await pool.query('SELECT * FROM job_positions ORDER BY id DESC');
    res.json(result.rows);
});
app.post('/api/jobs/import', upload.single('csv_file'), async (req, res) => {
    try {
        if (!req.file) return res.status(400).json({ error: 'Thi·∫øu file' });
        const results = [];
        const stream = require('stream').Readable.from(req.file.buffer);
        stream.pipe(csv()).on('data', (data) => results.push({
            title: data.Title || 'Job m·ªõi',
            requirements: { skills: data.Skills ? data.Skills.split('|') : [], experience: data.Experience || 0 },
            status: 'active'
        })).on('end', async () => {
            for (const job of results) await pool.query(`INSERT INTO job_positions (title, requirements, status) VALUES ($1, $2, 'active')`, [job.title, JSON.stringify(job.requirements)]);
            res.json({ message: "Done" });
        });
    } catch (err) { res.status(500).json({ error: err.message }); }
});
app.post('/api/training/upload', upload.single('doc_file'), async (req, res) => {
    try {
        if (!req.file) return res.status(400).json({ error: 'Thi·∫øu file' });
        let rawText = "";
        if (req.file.mimetype === 'application/pdf') rawText = await readPdfBuffer(req.file.buffer);
        else if (req.file.mimetype.includes('word')) { const r = await mammoth.extractRawText({ buffer: req.file.buffer }); rawText = r.value; }
        const chunks = chunkText(rawText);
        for (const chunk of chunks) {
            if(!chunk.trim()) continue;
            const vector = await createEmbedding(chunk);
            await pool.query(`INSERT INTO documents (content, metadata, embedding) VALUES ($1, $2, $3)`, [chunk, JSON.stringify({ filename: req.file.originalname }), `[${vector.join(',')}]`]);
        }
        res.json({ message: "Training Done" });
    } catch (err) { res.status(500).json({ error: err.message }); }
});
app.post('/api/training/chat', async (req, res) => {
    try {
        const { query } = req.body;
        const queryVector = await createEmbedding(query);
        const searchResult = await pool.query(`select content from match_documents($1, 0.5, 5)`, [`[${queryVector.join(',')}]`]);
        const context = searchResult.rows.map(r => r.content).join("\n---\n");
        const model = genAI.getGenerativeModel({ model: ACTIVE_MODEL_NAME });
        const result = await model.generateContent(`D·ª±a v√†o: ${context} \nTr·∫£ l·ªùi: ${query}`);
        res.json({ answer: result.response.text() });
    } catch (err) { res.status(500).json({ error: err.message }); }
});

const PORT = process.env.PORT || 5000;
app.listen(PORT, () => {
    console.log(`Server ch·∫°y t·∫°i c·ªïng ${PORT}`);
});